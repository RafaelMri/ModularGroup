\section{The modular group}

In this section and also later, we adopt the notation of \Schoeneberg{}.

\begin{definition}
\label{dfn_ModularGroup}
\index{Modular!group}
\index{Modular!transformation}
\index{Inhomogeneous!modular transformation}
A Möbius transformation $A$ of the form
\begin{equation*}
A(z) = \moebius{a}{b}{c}{d}{z},\quad a,b,c,d \in \Z,\quad ad - bc = 1
\end{equation*}
is called \emph{(inhomogeneous) modular transformation}.
\end{definition}

\begin{theorem}
\label{thm_ModularGroup}
\index{Modular!group}
The set of modular transformations forms a subgroup of the group of Möbius transformations and can be identified with the projective special linear group $\PSL{\Z}$. This group is called the \emph{modular group} and is denoted by $\ModGrp$.
\end{theorem}
\begin{proof}
The proof is very similar to that of Theorem \ref{thm_MoebiusGroup}. The only thing which has to be changed is the homomorphism $\pi$ defined in (\ref{eqn_homPi}). Its domain now is $\SL{\Z}$, the group of 2-by-2 matrices over $\Z$ with determinant 1, rather than $\GL{\C}$ (or $\SL{\C}$). Again it follows by the first isomorphism theorem, that the modular group $\ModGrp$ is isomorphic to $\SL{\Z} / \ker(\pi) \cong \PSL{\Z}$. The fact that $\ModGrp$ is a subgroup of the group of Möbius transformations is now also evident, since $\PSL{\Z} \le \PSL{\C} \cong \PGL{\C}$ (see Example~\ref{ex_ProjAndGenLinGrp}).
\end{proof}

\begin{remark}
\index{Inhomogeneous!modular transformation}
\index{Homogeneous!modular transformation}
\index{Modular!transformation}
The elements of $\SL{\Z}$ are often called \emph{homogeneous modular transformations}, whereas the transformations of $\ModGrp = \PSL{\Z}$ are called \emph{inhomogeneous transformations}. Strictly seen, an inhomogeneous transformation has to be denoted as $[M]_{\sim}$, which is the equivalence class in $\PSL{\Z}$ of a matrix $M \in \SL{\Z}$. It is clear, that $[M]_{\sim}$ is nothing but the set $\{\pm M\}$ and again for easier notation, we will from now on simply write either $M$ or $-M$ instead of $[M]_{\sim}$. Additionally we will denote equivalence of matrices by $\sim$, \ie if $\lambda = \pm 1$, then $M \sim \lambda M$.
\end{remark}

\todo{16}{Basic mapping properties}

\subsection{Generators and relations}
\label{sec_ModularGroupGenRel}

In group theory it is an important question, which presentations (in view of Definition~\ref{dfn_GrpConstructGenRel}) can be given for a fixed group $G$. This section is devoted to the investigation of this question in the case of the modular group.

Before we start, we introduce the following three important modular transformations which will be used very frequently from now on:

\begin{definition}We denote by $U$, $T$ and $R$ the following modular transformations:
\label{dfn_ModGrpBasicTransforms}
\begin{IEEEeqnarray*}{RL}
U: & z \mapsto z + 1 \\
T: & z \mapsto -\reci{z} \\
R = TU: & z \mapsto -\reci{z + 1}
\end{IEEEeqnarray*}
\end{definition}

\begin{remark}
Unfortunately, in literature there is no consensus on the notation of these transformations. We use the notation of \Schoeneberg{} here, but other notations are frequent. For example in \Klein{}, the symbol $S$ is used instead of $U$ and in other literature as well as on Wikipedia, additionally the roles of $S$ and $T$ are swapped.
\end{remark}

\begin{theorem}
\label{thm_ModGrpTUGen}
The modular group is generated by the elements $U: z \mapsto z+1$ and $T: z \mapsto -\reci{z}$. 
\end{theorem}
\begin{proof}
Let $A: z \mapsto \moebius{a}{b}{c}{d}{z}$ be an arbitrary modular transformation. Our goal is to show that $A$ can be written as product of the transformations $U$ and $T$. For this purpose it is more convenient to view these transformations as elements of $\PSL{\Z}$, namely
\begin{equation*}
A = \mat{a}{b}{c}{d}, \quad U = \mat{1}{1}{0}{1}, \quad T = \mat{0}{-1}{1}{\phantom{+}0}.
\end{equation*}

Let's first consider the two special cases, when $a$ or $c$ are zero. If $a=0$, it follows from $ad - bc = 1$, that $-b = c = \pm 1$. Therefore we have (equivalence of matrices is again denoted by $\sim$)
\begin{equation*}
A \sim c A = \mat{0}{-1}{1}{c d} = TU^{c d}.
\end{equation*}
Similarly, $c = 0$ gives $a = d = \pm 1$ and
\begin{equation*}
A \sim a A = \mat{1}{a b}{0}{1} = U^{a b}.
\end{equation*}
In the more general case, when $a$ and $c$ are both nonzero, $ad - bc = 1$ implies that $a$ and $c$ are coprime and the Euclidean algorithm therefore yields
\begin{eqnarray*}
      a &=& q_0 \cdot c\phantom{_0} + r_1 \\
      c &=& q_1 \cdot r_1 + r_2 \\
    r_1 &=& q_2 \cdot r_2 + r_3 \\
        &\vdots& \\
r_{n-1} &=& q_n \cdot r_n + r_{n+1}\\
        &=& q_n \cdot 1\phantom{_n} + 0.
\end{eqnarray*}
We can use this to reduce the Matrix $A$ by successively multiplying powers of $U$ and $T$ from the left. Just note, that multiplication with $U^k$ adds $k$ times the second row to the first row, whereas $T$ swaps the rows and changes the sign of one arbitrary row.\footnote{This freedom of choice is again due to the fact that the matrices $M$ and $-M$ represent the same element in $\PSL{\Z}$.} If we concentrate only on the first column of $A$ and apply the first few transformations
\begin{equation*}
\cvec{a}{c}                           \overset{U^{-q_0}}{\longmapsto}
\cvec{r_1}{c\phantom{_1}}             \overset{T}{\mapsto} 
\cvec{\phantom{+}c\phantom{_1}}{-r_1} \overset{U^{q_1}}{\longmapsto}
\cvec{\phantom{+}r_2}{-r_1}           \overset{T}{\mapsto} 
\cvec{r_1}{r_2}                       \overset{U^{-q_2}}{\longmapsto}
\cvec{r_3}{r_2}                       \overset{T}{\mapsto}
\cvec{\phantom{+}r_2}{-r_3}           \mapsto \dots,
\end{equation*}
we soon recognize the general mapping rule, which is
\begin{IEEEeqnarray*}{rCll}
\cvec{\phantom{+}r_{j-1}}{\phantom{+}r_{j\phantom{+0}}} 
& \overset{TU^{-q_j}}{\longmapsto}
& \cvec{\phantom{+}r_{j\phantom{+0}}}{-r_{j+1}}
& \quad \text{for even } j \text{ and}\\
\cvec{\phantom{+}r_{j-1}}{-r_{j\phantom{+0}}}
& \overset{TU^{q_j}}{\longmapsto}
& \cvec{\phantom{+}r_{j\phantom{+0}}}{\phantom{+}r_{j+1}} 
& \quad \text{for odd } j.
\end{IEEEeqnarray*}
When we set $r_{-1} := a$ and $r_0 := c$, this rule is applicable for $0 \le j \le n$. Obviously the described procedure ends with
\begin{equation*}
\cdots \overset{T}{\mapsto}
\cvec{\phantom{+}r_{n\phantom{+0}}}{\pm r_{n+1}} = \cvec{1}{0}.
\end{equation*} 
Because we know the first column of the resulting matrix and its determinant, which is 1, we can conclude that for some $k \in \Z$ it must have the form
\begin{equation*}
\mat{1}{k}{0}{1} = U^k.
\end{equation*}
By setting $e_n := (-1)^{n} q_n$ we therefore have 
\begin{equation*}
TU^{-e_n} TU^{-e_{n-1}} \cdots TU^{-e_1}TU^{-e_0} A = U^k,
\end{equation*}
or equivalently -- noting that $\inv{T} = T$, 
\begin{equation*}
A = U^{e_0} TU^{e_1} \cdots TU^{e_{n-1}} TU^{e_n} T U^k,
\end{equation*}
which gives the desired representation of $A$ in terms of $U$ and $T$ in the case when $a$ and $c$ are both nonzero.
\end{proof}

It is worth formulating the algorithm used in the previous proof explicitly in the following corollary.
\begin{corollary}
\label{cor_ModGrpTUAlg}
An arbitrary modular transformation $A: z \mapsto \moebius{a}{b}{c}{d}{z}$ can be represented as product of the transformations $U: z \mapsto z+1$ and $T : z \mapsto -\reci{z}$, by performing the following steps:
\begin{enumerate}
\item If $a = 0$, then $A = TU^{c d}$ and if $c = 0$, then $A = U^{a b}$ and we are done. Otherwise, continue with \ref{itm_ModGrpTUAlgStart}.
\item \label{itm_ModGrpTUAlgStart} Apply the Euclidean algorithm to $a$ and $c$ with the first division being $a = q_0 \cdot c + r_1$ ($q_0$ may be $\le 0$) and let $n$ be the number of the  last division (start counting from 0). Call the arising quotients $q_0,q_1,\dots,q_n$.
\item For $j \in \{0,1,\dots,n\}$ set $e_j := (-1)^j q_j$.
\item Calculate the matrix product $TU^{-e_n} TU^{-e_{n-1}} \cdots TU^{-e_1}TU^{-e_0} A$ and multiply by $\pm 1$ in order to obtain a representation with positive diagonal elements. Read off the right-upper entry and call it $k$.
\end{enumerate}
The transformation $A$ can now be written as
\begin{equation}
\label{eqn_ModGrpTUAlg}
A = U^{e_0} TU^{e_1} \cdots TU^{e_{n-1}} TU^{e_n} T U^k.
\end{equation}
\end{corollary}

\begin{remark}
\label{rem_EuclideanAlgorithmRounding}
The product representation (\ref{eqn_ModGrpTUAlg}) is not unique. In fact there is quite some freedom of choice for the quotients $q_0, q_1, \ldots, q_n$ in the algorithm of Corollary~\ref{cor_ModGrpTUAlg}. With the convention $r_{-1} := a$ and $r_0 := c$, one usually sets $q_j := \floor{\frac{r_{j-1}}{r_j}}$ for $j \ge 0$. The remainders, which are determined by 
\begin{equation}
\label{eqn_EuclideanAlgorithmLine}
r_{j+1} = r_{j-1} - q_j \cdot r_j \quad \text{for } j \ge 0,
\end{equation}
are then all nonnegative and form a strictly monotonic decreasing sequence,
\begin{equation*}
r_1 > r_2 > \ldots > r_n > r_{n+1} = 0.
\end{equation*}
All quotients, with the possible exception of $q_0$, are positive. In contrast to that, if we choose for each $j$ an arbitrary rounding direction (up- or downwards) and set $q_j$ to either $\floor{\frac{r_{j-1}}{r_j}}$ or $\ceil{\frac{r_{j-1}}{r_j}}$, then in general also negative remainders (and consequently negative quotients) will occur. Still, the absolute values of the remainders form a strictly monotonic decreasing sequence,
\begin{equation*}
\abs{r_1} > \abs{r_2} > \ldots > \abs{r_n} > \abs{r_{n+1}} = 0,
\end{equation*}
and therefore the Euclidean algorithm terminates and is correct.\footnote{The determined greatest common divisor is possibly negative, which is still admissible, because if $d$ is a greatest common divisor of $n,m \in \Z$, \ie $\forall d^\prime \in \Z: (d^\prime \mid n,m \Rightarrow d^\prime \mid d)$, then also $-d$ is.} Depending on the choice of the rounding directions we will in general obtain different product representations of $A$. Not only this, we can even go one step further and violate the constraint $\abs{r_j} > \abs{r_{j+1}}$ for a finite number of indices $j$ by choosing a completely random $q_j \in \Z$. As long as the remainders are calculated through (\ref{eqn_EuclideanAlgorithmLine}) all product representations obtained in this way are correct.
\end{remark}
\begin{example}
Consider the modular transformation $A \in \PSL{\Z}$ given by
\begin{equation*}
A = \mat{13}{5}{-8}{-3}.
\end{equation*}
Applying algorithm~\ref{cor_ModGrpTUAlg} and setting $q_j := \floor{\frac{r_{j-1}}{r_j}}$ for all $j$ yields the product representation
\begin{equation*}
A = U^{-2} TU^{-2} TU^1 TU^{-2} T.
\end{equation*}
In contrast to that, setting $q_j := \ceil{\frac{r_{j-1}}{r_j}}$ in each step leads to
\begin{equation*}
A = U^{-1} TU^1 TU^{-1} TU^1 TU^{-2} T.
\end{equation*}
Last, but not least, always rounding to the nearest integer gives the shortest representation:\footnote{It can be shown in general that rounding to the nearest integer always leads to a product representation with minimal number of factors $T$ and $U^k$, see [TODO 30]}
\begin{equation*}
A = U^{-2} TU^{-3} TU^{-3} T.
\end{equation*}
\end{example}

We have now seen that $T$ and $U$ generate the modular group and different product representations for a given modular transformation $A$ can be found using algorithm~\ref{cor_ModGrpTUAlg}. Of course the questions arises, which  relations (in sense of Definition~\ref{dfn_GrpConstructGenRel}) lie behind the ambiguity of these product representations. For example, it is easy to see that $T^2 = 1$ and $(TU)^3 = 1$ are relations which are satisfied by $T$ and $U$. It is the goal of the following paragraphs to show that these two relations are in fact the only ones in the sense that all other relations are derived from these. We will do this by proving the following theorem:

\begin{theorem}
\label{thm_ModGrpTRProd}
Let $T: z \mapsto -\reci{z}$ and $R = TU: z \mapsto -\reci{z+1}$. Every modular transformation $A \in \ModGrp$ can be written uniquely in the form
\begin{equation}
\label{eqn_ModGrpTRProd}
A = R^{k_1} T R^{k_2} T \cdots R^{k_{n-1}} T R^{k_n} 
\end{equation}
with $n \in \N$, $k_2,\dots,k_{n-1} \in \{\pm 1\}$ and $k_1, k_n \in \{0, \pm 1\}$.
\end{theorem}

From the uniqueness of the product representation (\ref{eqn_ModGrpTRProd}) it follows that we have in fact a \emph{presentation} of the modular group in the sense of Definition~\ref{dfn_GrpConstructGenRel}:

\begin{corollary}
\label{cor_ModGrpPresentation}
The modular group is generated by the elements $T: z \mapsto -\reci{z}$ and $R: z \mapsto -\reci{z+1}$ and can be presented as
\begin{equation}
\label{eqn_ModGrpPresentation}
\ModGrp \cong \presentation{T,R}{T^2 = R^3 = 1}.
\end{equation}
Therefore $\ModGrp$ is isomorphic to the free product of a cyclic group of order 2 and a cyclic group of order 3.
\end{corollary}
\begin{proof}
It is easy to see that the relations $T^2 = R^3 = 1$ are indeed satisfied:
\begin{eqnarray*}
T^2 &=& \mat{0}{-1}{1}{\phantom{-}0}^2 = \mat{-1}{\phantom{-}0}{\phantom{-}0}{-1} \sim \mat{1}{0}{0}{1}, \\
R^3 &=& \mat{0}{-1}{1}{\phantom{+}1}^3 = \mat{-1}{\phantom{-}0}{\phantom{-}0}{-1} \sim \mat{1}{0}{0}{1}.
\end{eqnarray*}
Moreover, the elements of $\presentation{T,R}{T^2 = R^3 = 1}$ are precisely the group words of the form~(\ref{eqn_ModGrpTRProd}), as we have seen in Examples~\ref{ex_RTGroup} and \ref{ex_RTFreeProd}.
\end{proof}

Before we turn to the proof of Theorem~\ref{thm_ModGrpTRProd}, we first make one helpful Definition and study its consequences.

\begin{definition}
\label{dfn_trsPredicates}
For a modular transformation $A: z \mapsto \moebius{a}{b}{c}{d}{z}$ we define the predicates $t$, $r$ and $s$ as well as a ``grading'' $n$:
\begin{IEEEeqnarray}{rCcCc}
\label{eqn_tpred}
t(A) &:\quad& ac \ge 0       &\quad\land\quad& bd \ge 0 \\
\label{eqn_rpred}
r(A) &:\quad& a^2 + ac \le 0 &\quad\land\quad& b^2 + bd \le 0 \\
\label{eqn_spred}
s(A) &:\quad& c^2 + ac \le 0 &\quad\land\quad& d^2 + bd \le 0
\end{IEEEeqnarray}
\begin{equation}
n(A) := a^2 + b^2 + c^2 + d^2.
\end{equation}
\end{definition}

Note, that $t$, $r$, $s$ and $n$ are well-defined, since they do not change their value if we switch from the matrix $A \in \PSL{\Z}$ to the equivalent matrix $-A$, \eg $t(A) \Leftrightarrow t(-A)$ and $n(A) = n(-A)$. Moreover, the predicates $t$, $r$, and $s$ partition the elements of the modular group into three classes:

\begin{lemma}
\label{lem_trsPartition}
Let $A: z \mapsto \moebius{a}{b}{c}{d}{z}$ be an arbitrary modular transformation. Then one, and only one of the predicates $t(A)$, $r(A)$ and $s(A)$ is satisfied.
\end{lemma}
\begin{proof}
We start by considering the two easiest cases first: If $A$ is the identity transformation or $A = T$, we have $t(A)$, $\lnot s(A)$ and $\lnot r(A)$.

For all other cases, we note that at least three of the coefficients $a,b,c,d$ are nonzero. Therefore, if one of the predicates $t(A)$, $r(A)$, $s(A)$ is satisfied, then at least one of the two inequalities involved is \emph{strictly} fulfilled. Having this said, it is easy to see that $t(A) \Rightarrow \lnot r(A) \land \lnot s(A)$. Thus it remains to show 
\begin{equation*}
\lnot t(A) \Rightarrow r(A) \lxor s(A),
\end{equation*}
for all transformations with at least three nonzero coefficients (here, $\lxor$ denotes logical exclusive or). If $t(A)$ is false, we have $ac < 0$ or $bd < 0$. Since both cases are completely symmetric, we may assume without restriction that $ac < 0$. Note, that $ac < 0$ and $ad - bc = 1$ implies $bd \le 0$ because otherwise if $bd > 0$, both nonzero terms $ad$ and $bc$ would have different  signs and their difference could not be 1. We conclude the proof by distinguishing three cases:
\begin{description}
\item[Case $a^2 < c^2$:] From $ac < 0$ it follows that $a^2 + ac < 0\ (i)$ and $c^2 + ac > 0\ (ii)$. Additionally, from $ad - bc = 1$ we can conclude that $b^2 \le d^2$, because otherwise $\abs{ad}$ would differ from $\abs{bc}$ by more than 1. Therefore we also have $b^2 + bd \le 0\ (iii)$. Taking these pieces together, we have $(ii) \Rightarrow \lnot s(A)$ and $(i) \land (iii) \Rightarrow r(A)$.
\item[Case $a^2 > c^2$:] This case is complementary to the first one: Because of $ac < 0$ we have $a^2 + ac > 0\ (i)$ and $c^2 + ac < 0\ (ii)$. The equation $ad - bc = 1$ here implies $b^2 \ge d^2$ and $d^2 + bd \le 0\ (iii)$. Thus we have $(i) \Rightarrow \lnot r(A)$ and $(ii) \land (iii) \Rightarrow s(A)$.
\item[Case $a^2 = c^2$:] Note that this case is only possible with $a = -c = \pm 1$ (as $a$ and $c$ are coprime). Hence we have $a^2 + ac = c^2 + ac = 0$. However, $ad - bc = 1$ implies $b^2 \ne d^2$ and therefore we have $b^2 + bd \le 0 \lxor d^2 + bd \le 0$. So, also in this case we have $r(A) \lxor s(A)$.\qedhere
\end{description}
\end{proof}

We have not yet seen the real benefit and meaning of the predicates $t$, $r$ and $s$. The following lemma will imply that they do nothing but indicate the leftmost symbol in the unique $R$-$T$ product representation (\ref{eqn_ModGrpTRProd}) of $A$. To be precise, if we denote this leftmost symbol by $\alpha(A)$, we will see that $t(A) \Leftrightarrow \alpha(A) = T$, $r(A) \Leftrightarrow \alpha(A) = R$ and $s(A) \Leftrightarrow \alpha(A) = \inv{R}$. Moreover, we will show that the grading $n(A)$ grows monotonically with the number of symbols $R$ and $\inv{R}$ in the product representation of $A$.

\begin{lemma}
\label{lem_trsnRelations}
The predicates $t$, $r$, $s$ and the grading $n$ satisfy the following relations:
\begin{enumerate}[\qquad(i)]
\item \label{itm_trsPropA}
$t(A) \Leftrightarrow r(RA) \Leftrightarrow s(\inv{R}A)$

\item \label{itm_trsPropB}
$t(A) \land t(TA) \Leftrightarrow A \in \{1,T\}$

\item \label{itm_trsPropC} 
$n(A) = n(TA)$

\item \label{itm_trsPropD}
$t(A) \Rightarrow n(A) < n(RA)\ \land\ n(A) < n(\inv{R}A)$

\end{enumerate}
\end{lemma}
\begin{proof}
For a better overview, we first write out the matrices corresponding to $TA$, $RA$ and $\inv{R}A$. Since $A = \smallmat{a}{b}{c}{d}$, $T = \smallmat{0}{-1}{1}{\phantom{-}0}$, $R = \smallmat{0}{-1}{1}{\phantom{+}1}$ and $\inv{R} = \smallmat{\phantom{+}1}{1}{-1}{0}$ these are:
\begin{equation*}
TA = \mat{-c}{-d}{\phantom{+}a}{\phantom{+}b},\quad RA = \mat{-c}{-d}{a+c}{b+d},\quad
\inv{R}A = \mat{a+c}{b+d}{-a}{-b}.
\end{equation*}
\begin{description}
\item[ad (\ref{itm_trsPropA}):] This is shown easily via two simple calculations:
\begin{IEEEeqnarray*}{rClCl}
r(RA)
&\Leftrightarrow& c^2 - c(a+c) \le 0 \land d^2 - d(b+d) \le 0 & &  \\
&\Leftrightarrow& ac \ge 0 \land bd \ge 0 &\Leftrightarrow& t(A) \\
s(\inv{R}A)
&\Leftrightarrow& a^2 - a(a+c) \le 0 \land b^2 - b(b+d) \le 0 & & \\
&\Leftrightarrow& ac \ge 0 \land bd \ge 0 &\Leftrightarrow& t(A)
\end{IEEEeqnarray*}
\item[ad (\ref{itm_trsPropB}):] It is immediate to see that $t(A) \land t(TA)$ is equivalent to $ac = bd = 0$. Clearly, 1 and $T$ are the only two transformations satisfying this condition.
\item[ad (\ref{itm_trsPropC}):] $n(A) = n(TA)$ is trivial.
\item[ad (\ref{itm_trsPropD}):] Note that $ad - bc = 1$ implies that at least one of the numbers $a$ and $b$ (resp.\ $c$ and $d$) is nonzero. Moreover, $t(A) \Rightarrow ac \ge 0 \land bd \ge 0$, and thus we have
\begin{IEEEeqnarray*}{+rCl+x*}
n(RA) - n(A)       &=& c^2 + 2ac + d^2 + 2bd > 0 \quad \text{and}\\
n(\inv{R}A) - n(A) &=& a^2 + 2ac + b^2 + 2bd > 0.&\qedhere
\end{IEEEeqnarray*}
\end{description}
\end{proof}

We can now formulate an algorithm, which yields a product representation of any arbitrary modular transformation in terms of the generators $R$ and $T$.

\begin{theorem}
\label{thm_ModGrpTRAlg}
For a modular transformation $A: z \mapsto \moebius{a}{b}{c}{d}{z}$, a product representation of the form (\ref{eqn_ModGrpTRProd}) can be found by performing the following steps:
\begin{enumerate}
\item Start with $k := 0$ and set $A_0 := A$.

\item If $A_k = 1$ go to step \ref{itm_ModGrpTRAlgFin}.
\label{itm_ModGrpTRAlgLoop}

\item Define $M_k$ as follows:
\label{itm_ModGrpTRAlgMDfn}
\begin{equation*}
t(A_k) \Rightarrow M_k := T,\quad
r(A_k) \Rightarrow M_k := R,\quad
s(A_k) \Rightarrow M_k := \inv{R}.
\end{equation*}

\item Set $A_{k+1} := M_k^{-1} A_k$, increment $k$ by one and continue with step \ref{itm_ModGrpTRAlgLoop}.
\label{itm_ModGrpTRAlgADfn}

\item If $k = 0$, then $A = 1$, which is the empty product. Otherwise, the desired product representation is $A = M_0 M_1 \cdots M_{k-1}$.
\label{itm_ModGrpTRAlgFin}
\end{enumerate}
\end{theorem}
\begin{proof}Note, that because of Lemma~\ref{lem_trsPartition}, the rule for the definition of the transformations $M_k$ from step \ref{itm_ModGrpTRAlgMDfn} is unambiguous and the described algorithm therefore yields a unique sequence of equations 
\begin{eqnarray*}
A_1 &=& M_0^{-1} A_0\\
A_2 &=& M_1^{-1} A_1\\
A_3 &=& M_2^{-1} A_2\\
    &\vdots&
\end{eqnarray*}
The relations (\ref{itm_trsPropA}) and (\ref{itm_trsPropB}) of Lemma~\ref{lem_trsnRelations} guarantee that for every pair of subsequent transformations $M_k$, $M_{k+1}$, one of them is $T$ and the other is either $R$ or $\inv{R}$. Additionally, the relations (\ref{itm_trsPropC}) and (\ref{itm_trsPropD}) imply $n(A_k) > n(A_{k+2})$. Since $n(1) = n(T) = 2$ is a lower bound for $n(A_k)$, the described procedure must terminate after a finite number $m$ of iterations and the product $A = M_0 M_1 \cdots M_{m-1}$ is indeed of the desired form (\ref{eqn_ModGrpTRProd}).
\end{proof}

Now have all tools in hand for the proof of Theorem~\ref{thm_ModGrpTRProd}. Note, that two alternative proofs can be found in \Schoeneberg{}, §4 and in \Klein{}, p.\ 452ff. 

\begin{proof}[Proof of Theorem \ref{thm_ModGrpTRProd}]
Let $A: z \mapsto \moebius{a}{b}{c}{d}{z}$ be an arbitrary modular transformation. The existence of a product representation of the form (\ref{eqn_ModGrpTRProd}) is ensured by the algorithm of Theorem~\ref{thm_ModGrpTRAlg}. 

In order to prove also its uniqueness, it is sufficient to show that the identity map has a unique product representation (namely the empty product). From the relations (\ref{itm_trsPropC}) and (\ref{itm_trsPropD}) of Lemma~\ref{lem_trsnRelations} we see that any product $P$ of the form (\ref{eqn_ModGrpTRProd}) containing at least one factor $R$ or $\inv{R}$ has a grading $n(P) > n(1) = 2$ and therefore $P \ne 1$. The only products which are free of factors $R$ and $\inv{R}$ are T and the empty product. Since $T \ne 1$, the identity map can indeed only be represented by the empty product. \qedhere
\end{proof}

We conclude this section with the final remark that algorithm~\ref{thm_ModGrpTRAlg} successively reduces a given matrix $A \in \PSL{\Z}$ by multiplication from the left with $T$, $R$ or $\inv{R}$. Of course, by using a dual approach also multiplication from the right can be used. All we have to do in order to adapt algorithm~\ref{thm_ModGrpTRAlg} appropriately is to substitute the predicates $t$, $r$, $s$ by predicates $t^{\prime}$, $r^{\prime}$, $s^{\prime}$ and to change the definition in step \ref{itm_ModGrpTRAlgADfn} from $A_{k+1} := M_k^{-1} A_k$ to $A_{k+1} := A_k M_k^{-1}$. But how do the predicates $t^{\prime}$, $r^{\prime}$ and $s^{\prime}$ have to be defined?

For this consideration we denote the leftmost symbol in the $R$-$T$ product representation (\ref{eqn_ModGrpTRProd}) of $A$ by $\alpha(A)$ and the rightmost symbol by $\omega(A)$. In the case of the empty product, we define $\alpha(1) := \omega(1) := T$. We have already seen, that $t(A) \Leftrightarrow \alpha(A) = T$, $r(A) \Leftrightarrow \alpha(A) = R$ and $s(A) \Leftrightarrow \alpha(A) = \inv{R}$. In correspondence to that, we see that we have to define 
\begin{IEEEeqnarray*}{RrClCrClCc}
t^{\prime}(A):\quad& \omega(A) &=& T 
              &\quad\Leftrightarrow\quad& \alpha(\inv{A}) &=& T
              &\quad\Leftrightarrow\quad& t(\inv{A}), \\
r^{\prime}(A):\quad& \omega(A) &=& R 
              &\quad\Leftrightarrow\quad& \alpha(\inv{A}) &=& \inv{R}
              &\quad\Leftrightarrow\quad& s(\inv{A}), \\
s^{\prime}(A):\quad& \omega(A) &=& \inv{R}
              &\quad\Leftrightarrow\quad& \alpha(\inv{A}) &=& R
              &\quad\Leftrightarrow\quad& r(\inv{A}).
\end{IEEEeqnarray*}
Written out explicitly, this gives for a matrix $A = \smallmat{a}{b}{c}{d} \in \PSL{\Z}$:
\begin{IEEEeqnarray}{rCcCc}
\label{eqn_trpred}
t^{\prime}(A) &:\quad& ab \le 0       &\quad\land\quad& cd \le 0 \\
\label{eqn_rrpred}
r^{\prime}(A) &:\quad& a^2 - ab \le 0 &\quad\land\quad& c^2 - cd \le 0 \\
\label{eqn_srpred}
s^{\prime}(A) &:\quad& b^2 - ab \le 0 &\quad\land\quad& d^2 - cd \le 0
\end{IEEEeqnarray}
Note, that also the Lemmas \ref{lem_trsPartition} and \ref{lem_trsnRelations} remain valid, if the predicates $t$, $r$, $s$ are substitued by $t^{\prime}$, $r^{\prime}$, $s^{\prime}$ and the order of matrix multiplication is reversed (\ie $RA$, $TA$, \dots\ have to be replaced by $AR$, $AT$, \dots).

% ------------------------------- Subsection: Fundamental domains, tessellation
\input{sub-fundomtess.tex}

% --------------------------------------------- Subsection: Hyperbolic geometry
\input{sub-hypgeom.tex}

% ------------------------------- Subsection: Ford circles, continued fractions
\input{sub-fordconf.tex}

% -------------------------------------- Subsection: Klein J invariant function

\subsection{The Klein modular invariant function $j$}

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figures/klein-j}
\caption{The composition of the Klein modular invariant function and the inverse modified Cayley transform $j \circ \inv{\ModCayley}$.}
\label{fig_KleinJ}
\end{figure}

\begin{figure}
\centering
\begin{tabular}{c c}
\includegraphics[width=0.4\textwidth]{figures/klein-jinv} &
\includegraphics[width=0.4\textwidth]{figures/klein-jm1} \\
\includegraphics[width=0.4\textwidth]{figures/klein-jsqr} &
\includegraphics[width=0.4\textwidth]{figures/klein-jfib}
\end{tabular}
\caption{The composition of the Klein modular invariant function and the inverse modified Cayley transform $j \circ \inv{\ModCayley}$.}
\label{fig_FunctionsOfJ}
\end{figure}
